# Paperless-NGX + Ollama AI Stack

Vollautomatisches Installations-Script fÃ¼r eine komplette Dokumentenverwaltungs-LÃ¶sung mit lokaler KI-Integration.

## ğŸ¯ Features

- **Paperless-NGX** - Moderne Dokumentenverwaltung mit OCR
- **Paperless-AI** - KI-gestÃ¼tzte Dokumentenanalyse und Klassifizierung
- **Ollama** - Lokale KI-Engine (keine Cloud-API erforderlich)
- **Gemma2:9B** - Leistungsstarkes Open-Source Sprachmodell
- **RAG-Chat** - Interaktive Dokumenten-Chats mit KI
- **OpenAI Whisper** - Integrierte Spracherkennung fÃ¼r Audio-Dateien
- **PostgreSQL + Redis** - Robuste Datenbank-Backend

## ğŸ“‹ Voraussetzungen

- **Betriebssystem**: Ubuntu 20.04+ / Debian 11+ / CentOS 8+ / Rocky Linux 8+
- **RAM**: Mindestens 8GB (16GB empfohlen fÃ¼r Ollama)
- **Festplatte**: Mindestens 20GB freier Speicher
- **CPU**: x64 Prozessor mit mindestens 4 Kernen
- **Root-Zugriff**: Das Script muss als root/sudo ausgefÃ¼hrt werden
- **Datenverzeichnis**: `/mnt/user/dokumente/paperless` muss existieren

## ğŸš€ Installation

### 1. Datenverzeichnis vorbereiten

```bash
# Datenverzeichnis erstellen (falls nicht vorhanden)
sudo mkdir -p /mnt/user/dokumente/paperless
sudo chown -R $USER:$USER /mnt/user/dokumente/paperless
```

### 2. Script herunterladen

```bash
# Script herunterladen
wget https://raw.githubusercontent.com/KaiserUndGott/Paperless_Ollama_Stack/main/install_v12.sh

# AusfÃ¼hrbar machen
chmod +x install_v12.sh
```

### 3. Installation starten

```bash
sudo ./install_v12.sh
```

Das Script wird Sie durch die Installation fÃ¼hren und folgende Informationen abfragen:

- **Admin-Benutzername** (min. 3 Zeichen)
- **Admin-Passwort** (min. 12 Zeichen mit GroÃŸ-/Kleinbuchstaben, Zahlen und Sonderzeichen)

### 4. Installation Ã¼berwachen

Die Installation dauert ca. 15-20 Minuten, abhÃ¤ngig von Ihrer Internetverbindung (ca. 5-6GB Download fÃ¼r Ollama + Gemma2:9B).

## ğŸ”§ Konfiguration

### Port-Konfiguration

Das Script sucht automatisch nach freien Ports. Standard-Ports:

- **Paperless-NGX**: 8000
- **Paperless-AI**: 3000
- **Ollama API**: 11434
- **PostgreSQL**: 5432
- **Redis**: 6379

### Volumes

Alle Paperless-Daten werden in `/mnt/user/dokumente/paperless` gespeichert:

```
/mnt/user/dokumente/paperless/
â”œâ”€â”€ data/           # Datenbank-Dateien und Metadaten
â”œâ”€â”€ media/          # Originaldokumente und verarbeitete Dateien
â”œâ”€â”€ export/         # Exportierte Dokumente
â””â”€â”€ consume/        # Upload-Ordner fÃ¼r neue Dokumente
```

Container-spezifische Daten werden in `/opt/paperless-stack/data` gespeichert:

```
/opt/paperless-stack/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ postgres/        # PostgreSQL Datenbank
â”‚   â”œâ”€â”€ redis/           # Redis Datenbank
â”‚   â”œâ”€â”€ ollama/          # Ollama Modelle und Konfiguration
â”‚   â””â”€â”€ paperless-ai/    # Paperless-AI Daten
â””â”€â”€ config/
    â””â”€â”€ paperless-ai/    # Paperless-AI Konfiguration
```

## ğŸ“š Verwendung

### Zugriff auf die Web-Interfaces

Nach erfolgreicher Installation:

1. **Paperless-NGX**: `http://[SERVER-IP]:8000`
   - Login mit den bei der Installation angegebenen Credentials
   - Dokumente hochladen, verwalten und durchsuchen

2. **Paperless-AI**: `http://[SERVER-IP]:3000`
   - Setup-Assistent beim ersten Besuch durchlaufen
   - KI-Features fÃ¼r Dokumentenanalyse nutzen

3. **Ollama API**: `http://[SERVER-IP]:11434`
   - API-Endpoint fÃ¼r direkte Ollama-Anfragen

### Tags und automatische Verarbeitung

- **"Neu"-Tag**: Wird automatisch allen neuen Dokumenten zugewiesen und triggert die KI-Verarbeitung
- **"RAG"-Tag**: Manuell fÃ¼r Dokumente setzen, die im RAG-Chat verfÃ¼gbar sein sollen

### RAG-Chat verwenden

1. Dokumente in Paperless-NGX mit "RAG"-Tag markieren
2. In Paperless-AI den Chat Ã¶ffnen
3. Fragen zu Ihren Dokumenten stellen - die KI antwortet basierend auf dem Dokumenteninhalt

### Ollama Modelle verwalten

```bash
# In den Stack-Ordner wechseln
cd /opt/paperless-stack

# Installierte Modelle anzeigen
docker exec paperless-ollama ollama list

# Neues Modell herunterladen
docker exec paperless-ollama ollama pull <model-name>

# Modell interaktiv testen
docker exec -it paperless-ollama ollama run gemma2:9b
```

## ğŸ› ï¸ Management

### Container verwalten

```bash
# In den Stack-Ordner wechseln
cd /opt/paperless-stack

# Status aller Container anzeigen
docker compose ps

# Logs anzeigen
docker compose logs -f

# Alle Container stoppen
docker compose down

# Alle Container starten
docker compose up -d

# Einzelnen Container neustarten
docker compose restart <service-name>
```

### Backup erstellen

```bash
# VollstÃ¤ndiges Backup (Paperless-Daten + Stack-Konfiguration)
sudo tar -czf paperless-backup-$(date +%Y%m%d).tar.gz \
  /mnt/user/dokumente/paperless \
  /opt/paperless-stack

# Nur Paperless-Daten sichern
sudo tar -czf paperless-data-backup-$(date +%Y%m%d).tar.gz \
  /mnt/user/dokumente/paperless
```

### Updates durchfÃ¼hren

```bash
cd /opt/paperless-stack

# Images aktualisieren
docker compose pull

# Container mit neuen Images neu starten
docker compose up -d
```

## ğŸ” Troubleshooting

### Container startet nicht

```bash
# Logs des problematischen Containers anzeigen
docker compose logs <service-name>

# Container neu erstellen
docker compose up -d --force-recreate <service-name>
```

### Ollama Modell fehlt

```bash
# Gemma2:9B Modell manuell herunterladen
docker exec paperless-ollama ollama pull gemma2:9b
```

### Paperless-AI kann nicht auf Paperless-NGX zugreifen

```bash
# API Token Ã¼berprÃ¼fen
cat /opt/paperless-stack/config/paperless-ai/.env | grep PAPERLESS_API_TOKEN

# Container neu starten
docker compose restart paperless-ai
```

### Speicherplatz prÃ¼fen

```bash
# Docker Speichernutzung anzeigen
docker system df

# Nicht verwendete Images/Container/Volumes entfernen
docker system prune -a --volumes
```

## ğŸ“– Technische Details

### Stack-Komponenten

| Komponente | Image | Port | Beschreibung |
|------------|-------|------|--------------|
| Paperless-NGX | ghcr.io/paperless-ngx/paperless-ngx:latest | 8000 | Dokumentenverwaltung |
| Paperless-AI | clusterzx/paperless-ai:latest | 3000 | KI-Integration |
| Ollama | ollama/ollama:latest | 11434 | Lokale KI-Engine |
| PostgreSQL | postgres:15-alpine | 5432 | Datenbank |
| Redis | redis:7-alpine | 6379 | Cache |

### Netzwerk

Alle Container sind im Docker-Netzwerk `paperless-net` verbunden und kÃ¶nnen Ã¼ber ihre Service-Namen kommunizieren.

### Ressourcen-Anforderungen

| Komponente | RAM | CPU | Disk |
|------------|-----|-----|------|
| Paperless-NGX | 1-2 GB | 1-2 Cores | 2 GB |
| Paperless-AI | 512 MB | 1 Core | 1 GB |
| Ollama + Gemma2:9B | 4-6 GB | 2-4 Cores | 6 GB |
| PostgreSQL | 256 MB | 1 Core | 1 GB |
| Redis | 128 MB | 1 Core | 100 MB |

**Gesamt**: ~8-10 GB RAM, 4-6 CPU-Cores, ~20 GB Festplatte

## ğŸ¤ BeitrÃ¤ge

BeitrÃ¤ge, Issues und Feature-Requests sind willkommen!

## ğŸ“„ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert.

## ğŸ™ Credits

- [Paperless-NGX](https://github.com/paperless-ngx/paperless-ngx)
- [Paperless-AI](https://github.com/clusterzx/paperless-ai)
- [Ollama](https://github.com/ollama/ollama)
- [Gemma2](https://ai.google.dev/gemma)

## ğŸ“ Support

Bei Fragen oder Problemen erstellen Sie bitte ein Issue in diesem Repository.

---

**Version**: 12.0
**Stand**: 25.11.2025
**Autor**: FBW
